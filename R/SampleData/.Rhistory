##Mood DV
## enter the coefficients and n's into r as objects
rs=c(.21,.23,.326,-.135,-.043,-.039)
ns=c(35,154,43,40,151,50)
## assign a moderator level to the groups of correlations
type=c(1,1,1,0,0,0)
## load the necessary libraries
library(metafor)
library(psych)
## compute the effect sizes (after r-to-z transformation)
meta_rs=escalc("ZCOR",ri=rs,ni=ns)
meta_rs$type<-type
## do the meta-analysis
meta=rma(yi=yi,vi=vi,data=meta_rs,mods=type)
meta
## convert estimates back from z to r
fisherz2r(coef(meta))
fisherz2r(meta$ci.lb)
fisherz2r(meta$ci.ub)
## The test of moderation is significant (p = .0011, the correlations of set 1 are different from set 2
## The correlations in set 1 are significantly greater than zero (r = .298, 95% CI = [.122, .454])
## The correlations in set 2 are not significantly different than zero (r = -.057, 95% CI = [-.184, .072])
##repeat next step â€“ clear console first
i = c(.056,.249,-.094,-.089)
n=c(154,43,151,50)
## assign a moderator level to the groups of correlations
typei=c(1,1,0,0)
## load the necessary libraries
library(metafor)
library(psych)
## compute the effect sizes (after r-to-z transformation)
meta_i=escalc("ZCOR",ri=i,ni=n)
meta_i$type=typei
## do the meta-analysis
meta=rma(yi=yi,vi=vi,data=meta_i,mods=typei)
meta
## convert estimates back from z to r
fisherz2r(coef(meta))
fisherz2r(meta$ci.lb)
fisherz2r(meta$ci.ub)
## The test of moderation is marginally significant (p = .0611)
## The correlations in set 1 are significantly greater than zero (r = .188, 95% CI = [-.009, .372])
## The correlations in set 2 are not significantly different than zero (r = -.093, 95% CI = [-.229, .047])
ls
rm(ls)
ls
cls
cat("\014")
ls
ls()
rm(ls())
ls()
rm(list=ls())
cat("\014")
# Remove all saved variables in the console
# Remove all saved variables in the console
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
cat("\014")
source('~/Jinhyung.R', echo=TRUE)
install.packages("metafor")
cat("\014")
install.packages('MTurkR')
library('irr')
citation(package="irr")
iris
install.packages('ggvis')
library('ggvis')
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill = ~Species) %>% layer_points()
iris %>% ggvis(~Petal.Length, ~Petal.Width, fill = ~Species) %>% layer_points()
head(iris)
str(iris)
count(iris)
library('plyr')
count(iris)
count(iris$Species)
?plyr
summarise(iris)
summarise(iris$Sepal.Length)
str(iris$Sepal.Length)
summary(iris)
# Getting an idea of structure
head(iris)
str(iris)
summary(iris)
std(iris)
sd(iris)
sd(iris$.)
sd(iris$Sepal.Length)
sd(c(iris$Sepal.Length, iris$Sepal.Width, iris$Petal.Length, iris$Petal.Width))
summary(iris)
install.packages('psych')
library('psych')
describe(iris)
describe.by(iris, Species)
describeBy(iris, iris$Species)
summary(iris)
install.packages("class")
library("class")
normalize <- function(n) {
num <- n - min(n)
denom <- max(n) - min(n)
return (num/denom)
}
iris_n <- as.data.frame(lapply(iris[1:4], normalize))
describeBy(iris_n, iris$Species)
describe(iris_n)
t.split <- sample(2, nrow(iris), replace=TRUE, prob=c(.67, .33))
set.seed(1337)
# Splitting into a train and test set with proportional split
t.split <- sample(2, nrow(iris), replace=TRUE, prob=c(.67, .33))
iris.train <- iris[t.split==1, 1:4] # There are four variables to be split in iris
iris.test <- iris[t.split==2, 1:4]
iris.trainLabels <- iris[ind==1, 5] # Storing the class labels
iris.testLabels <- iris[ind==2, 5]
# Splitting into a train and test set with proportional split
t.split <- sample(2, nrow(iris), replace=TRUE, prob=c(.67, .33))
iris.train <- iris[t.split==1, 1:4] # There are four variables to be split in iris
iris.test <- iris[t.split==2, 1:4]
iris.trainLabels <- iris[t.split==1, 5] # Storing the class labels
iris.testLabels <- iris[t.split==2, 5]
knn(train=iris.train, test=iris.test, cl = iris.trainLabels, k=3)
iris.train
cbind(iris.trainLabels, iris_p)
iris_p <-knn(train=iris.train, test=iris.test, cl = iris.trainLabels, k=3)
cbind(iris.trainLabels, iris_p)
cbind(iris.train, iris.test)
cbind(iris.pred, iris.testLabels)
cbind(iris.p, iris.testLabels)
cbind(iris_p, iris.testLabels)
cbind(iris_p, iris.testLabels, iris_p==iris.testLabels)
match <- iris_p==iris.testLabels
cbind(iris_p, iris.testLabels, match)
as.data.frame(cbind(iris_p, iris.testLabels, match))
mean(match)
df_m<-cbind(iris_p, iris.testLabels, match)
mean(df_m$match)
df_m<-cbind(iris_p, iris.testLabels, match)
mean(df_m$match)
df_m<-data.frame(iris_p, iris.testLabels, match)
mean(df_m$match)
library("MASS")
tbl<- table(iris$testLabels, iris_p, useNA="no")
tbl<- table(iris.testLabels, iris_p, useNA="no")
tbl
chisq.test(tbl)
CrossTable(x = iris.testLabels, y = iris_p, prop.chisq=TRUE)
install.packages('gmodels')
library('gmodels')
CrossTable(x = iris.testLabels, y = iris_p, prop.chisq=TRUE)
cat("This model classifies at", m*100, "percent accuracy")
m<-mean(df_m$match)
cat("This model classifies at", m*100, "percent accuracy")
cat("This model classifies at", round(m*100, digits=2), "percent accuracy")
length(iris.testLabels)
count(iris.testLabels)
length(count(iris.testLabels))
lengths(count(iris.testLabels))
unique(iris.test)
unique(iris.testLabels)
length(unique(iris.testLabels))
cat("This model classifies at", round(m*100, digits=2),
"percent accuracy, compared to random chance:", 1/length(unique(iris.testLabels)))
cat("This model classifies at", round(m*100, digits=2),
"percent accuracy, compared to random chance:", round(1/length(unique(iris.testLabels))), digits=2)
cat("This model classifies at", round(m*100, digits=2),
"percent accuracy, compared to random chance:", round(1/length(unique(iris.testLabels)), digits=2))
cat("This model classifies at", round(m*100, digits=2),
"percent accuracy, compared to random chance:", round(1/length(unique(iris.testLabels))*100, digits=2)
)
cat("This model classifies at", round(m*100, digits=2),
"percent accuracy, compared to random chance:",
round(1/length(unique(iris.testLabels))*100, digits=2), "percent"
)
##############################################################################################################
# K-Nearest Neighbor (KNN)
# Date of Creation: 04/09/2017
# Created by Tom Tibbett
# This script conducts KNN on the Iris sample data set.  It also includes simple ways to explore/visualize data
# Libraries include psych, ggvis, class, and gmodels.
##############################################################################################################
# Data Exploration
##############################################################################################################
# Clear the Environment
rm(list=ls())
# Working Directory
getwd()
setwd("F:/Python Scripts/UsefulCode/R/SampleData/")
# install.packages('psych')
library('psych')
# Getting an idea of structure
head(iris)
str(iris)
summary(iris)
describe(iris)
describeBy(iris, iris$Species)
# install.packages('ggvis')
library('ggvis')
# Plotting- separating by flower species and reviewing the overall pattern
## Sepal
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill = ~Species) %>% layer_points()
## Petal
iris %>% ggvis(~Petal.Length, ~Petal.Width, fill = ~Species) %>% layer_points()
# install.packages("class") # Library for KNN
library("class")
# Creating a normalization function just in case there are high ranges that do not overlap
normalize <- function(n) {
num <- n - min(n)
denom <- max(n) - min(n)
return (num/denom)
}
# Not a need for this data set to normalize, but in case we need it for others...
iris_n <- as.data.frame(lapply(iris[1:4], normalize))
describe(iris_n) # Note the min and max
describeBy(iris_n, iris$Species)
##############################################################################################################
# Machine Learning
##############################################################################################################
# Preparation
set.seed(1337)
# Splitting into a train and test set with proportional split
t.split <- sample(2, nrow(iris), replace=TRUE, prob=c(.67, .33))
iris.train <- iris[t.split==1, 1:4] # There are four variables to be split in iris
iris.test <- iris[t.split==2, 1:4]
iris.trainLabels <- iris[t.split==1, 5] # Storing the class labels for Species
iris.testLabels <- iris[t.split==2, 5]
# Building a classifier
iris_p <-knn(train=iris.train, test=iris.test, cl = iris.trainLabels, k=3)
match <- iris_p==iris.testLabels # How often do they match?
df_m<-data.frame(iris_p, iris.testLabels, match)
m<-mean(df_m$match)
# Contingency Tables
# install.packages('gmodels')
library('gmodels')
CrossTable(x = iris.testLabels, y = iris_p, prop.chisq=TRUE)
cat("This model classifies at", round(m*100, digits=2),
"percent accuracy, compared to random chance:",
round(1/length(unique(iris.testLabels))*100, digits=2), "percent"
)
##############################################################################################################
# K-Nearest Neighbor (KNN)
# Date of Creation: 04/09/2017
# Created by Tom Tibbett
# This script conducts KNN on the Iris sample data set.  It also includes simple ways to explore/visualize data
# Libraries include psych, ggvis, class, and gmodels.
##############################################################################################################
# Data Exploration
##############################################################################################################
# Clear the Environment
rm(list=ls())
# Working Directory
getwd()
setwd("F:/Python Scripts/UsefulCode/R/SampleData/")
# install.packages('psych')
library('psych')
# Getting an idea of structure
head(iris)
str(iris)
summary(iris)
describe(iris)
describeBy(iris, iris$Species)
# install.packages('ggvis')
library('ggvis')
# Plotting- separating by flower species and reviewing the overall pattern
## Sepal
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill = ~Species) %>% layer_points()
## Petal
iris %>% ggvis(~Petal.Length, ~Petal.Width, fill = ~Species) %>% layer_points()
# install.packages("class") # Library for KNN
library("class")
# Creating a normalization function just in case there are high ranges that do not overlap
normalize <- function(n) {
num <- n - min(n)
denom <- max(n) - min(n)
return (num/denom)
}
# Not a need for this data set to normalize, but in case we need it for others...
iris_n <- as.data.frame(lapply(iris[1:4], normalize))
describe(iris_n) # Note the min and max
describeBy(iris_n, iris$Species)
##############################################################################################################
# Machine Learning
##############################################################################################################
# Preparation
set.seed(1234)
# Splitting into a train and test set with proportional split
t.split <- sample(2, nrow(iris), replace=TRUE, prob=c(.67, .33))
iris.train <- iris[t.split==1, 1:4] # There are four variables to be split in iris
iris.test <- iris[t.split==2, 1:4]
iris.trainLabels <- iris[t.split==1, 5] # Storing the class labels for Species
iris.testLabels <- iris[t.split==2, 5]
# Building a classifier
iris_p <-knn(train=iris.train, test=iris.test, cl = iris.trainLabels, k=3)
match <- iris_p==iris.testLabels # How often do they match?
df_m<-data.frame(iris_p, iris.testLabels, match)
m<-mean(df_m$match)
# Contingency Tables
# install.packages('gmodels')
library('gmodels')
CrossTable(x = iris.testLabels, y = iris_p, prop.chisq=TRUE)
cat("This model classifies at", round(m*100, digits=2),
"percent accuracy, compared to random chance:",
round(1/length(unique(iris.testLabels))*100, digits=2), "percent"
)
##############################################################################################################
# K-Nearest Neighbor (KNN)
# Date of Creation: 04/09/2017
# Created by Tom Tibbett
# This script conducts KNN on the Iris sample data set.  It also includes simple ways to explore/visualize data
# Libraries include psych, ggvis, class, and gmodels.
##############################################################################################################
# Data Exploration
##############################################################################################################
# Clear the Environment
rm(list=ls())
# Working Directory
getwd()
setwd("F:/Python Scripts/UsefulCode/R/SampleData/")
# install.packages('psych')
library('psych')
# Getting an idea of structure
head(iris)
str(iris)
summary(iris)
describe(iris)
describeBy(iris, iris$Species)
# install.packages('ggvis')
library('ggvis')
# Plotting- separating by flower species and reviewing the overall pattern
## Sepal
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill = ~Species) %>% layer_points()
## Petal
iris %>% ggvis(~Petal.Length, ~Petal.Width, fill = ~Species) %>% layer_points()
# install.packages("class") # Library for KNN
library("class")
# Creating a normalization function just in case there are high ranges that do not overlap
normalize <- function(n) {
num <- n - min(n)
denom <- max(n) - min(n)
return (num/denom)
}
# Not a need for this data set to normalize, but in case we need it for others...
iris_n <- as.data.frame(lapply(iris[1:4], normalize))
describe(iris_n) # Note the min and max
describeBy(iris_n, iris$Species)
##############################################################################################################
# Machine Learning
##############################################################################################################
# Preparation
set.seed(1234)
# Splitting into a train and test set with proportional split
t.split <- sample(2, nrow(iris), replace=TRUE, prob=c(.67, .33))
iris.train <- iris[t.split==1, 1:4] # There are four variables to be split in iris
iris.test <- iris[t.split==2, 1:4]
iris.trainLabels <- iris[t.split==1, 5] # Storing the class labels for Species
iris.testLabels <- iris[t.split==2, 5]
# Building a classifier
iris_p <-knn(train=iris.train, test=iris.test, cl = iris.trainLabels, k=3)
match <- iris_p==iris.testLabels # How often do they match?
df_m<-data.frame(iris_p, iris.testLabels, match)
m<-mean(df_m$match)
# Contingency Tables
# install.packages('gmodels')
library('gmodels')
CrossTable(x = iris.testLabels, y = iris_p, prop.chisq=TRUE)
cat("This model classifies at", round(m*100, digits=2),
"percent accuracy, compared to random chance:",
round(1/length(unique(iris.testLabels))*100, digits=2), "percent"
)
